{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DustoKinetic/Dusty_anus/blob/main/Copy_of_Z_Image_Turbo_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hisWToHSCzC"
      },
      "source": [
        "## Build Docker Image and Push to Google Container Registry\n",
        "\n",
        "### Subtask:\n",
        "Build the Docker image for the ComfyUI API using the provided Dockerfile and app.py, and push it to your Google Container Registry (GCR).\n",
        "\n",
        "#### Instructions\n",
        "1. Ensure you are authenticated to Google Cloud. If you haven't already, run `gcloud auth login` in your terminal and follow the prompts.\n",
        "2. Set your Google Cloud Project ID. Replace `YOUR_PROJECT_ID` with your actual Google Cloud Project ID by running: `gcloud config set project YOUR_PROJECT_ID`.\n",
        "3. Navigate to the directory where your `Dockerfile` and `app.py` are located.\n",
        "4. Submit the Dockerfile to Cloud Build to build the image and push it to Google Container Registry. Run the following command, replacing `YOUR_PROJECT_ID` with your Google Cloud Project ID: `gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:latest .`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_GAwuj2SEoN"
      },
      "source": [
        "## Build Docker Image and Push to Google Container Registry\n",
        "\n",
        "### Subtask:\n",
        "Build the Docker image for the ComfyUI API using the provided Dockerfile and app.py, and push it to your Google Container Registry (GCR).\n",
        "\n",
        "#### Instructions\n",
        "1. Ensure you are authenticated to Google Cloud. If you haven't already, run `gcloud auth login` in your terminal and follow the prompts.\n",
        "2. Set your Google Cloud Project ID. Replace `YOUR_PROJECT_ID` with your actual Google Cloud Project ID by running: `gcloud config set project YOUR_PROJECT_ID`.\n",
        "3. Navigate to the directory where your `Dockerfile` and `app.py` are located.\n",
        "4. Submit the Dockerfile to Cloud Build to build the image and push it to Google Container Registry. Run the following command, replacing `YOUR_PROJECT_ID` with your Google Cloud Project ID: `gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:latest .`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E1ZejeOfHopf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cb5b53-7823-46f0-d56f-a6964f116bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 28191, done.\u001b[K\n",
            "remote: Counting objects: 100% (234/234), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 28191 (delta 172), reused 89 (delta 89), pack-reused 27957 (from 3)\u001b[K\n",
            "Receiving objects: 100% (28191/28191), 75.02 MiB | 8.99 MiB/s, done.\n",
            "Resolving deltas: 100% (19051/19051), done.\n",
            "/content/ComfyUI\n",
            "Collecting comfyui-frontend-package==1.33.10 (from -r requirements.txt (line 1))\n",
            "  Downloading comfyui_frontend_package-1.33.10-py3-none-any.whl.metadata (118 bytes)\n",
            "Collecting comfyui-workflow-templates==0.7.25 (from -r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates-0.7.25-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting comfyui-embedded-docs==0.3.1 (from -r requirements.txt (line 3))\n",
            "  Downloading comfyui_embedded_docs-0.3.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.9.0+cu126)\n",
            "Collecting torchsde (from -r requirements.txt (line 5))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.50.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.57.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.22.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.2.1)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: aiohttp>=3.11.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (3.13.2)\n",
            "Requirement already satisfied: yarl>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.22.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (6.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (5.9.5)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (1.17.2)\n",
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (2.0.44)\n",
            "Collecting av>=14.2.0 (from -r requirements.txt (line 23))\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting kornia>=0.7.1 (from -r requirements.txt (line 26))\n",
            "  Downloading kornia-0.8.2-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting spandrel (from -r requirements.txt (line 27))\n",
            "  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (2.12.3)\n",
            "Requirement already satisfied: pydantic-settings~=2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (2.12.0)\n",
            "Collecting comfyui-workflow-templates-core==0.3.12 (from comfyui-workflow-templates==0.7.25->-r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates_core-0.3.12-py3-none-any.whl.metadata (259 bytes)\n",
            "Collecting comfyui-workflow-templates-media-api==0.3.14 (from comfyui-workflow-templates==0.7.25->-r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates_media_api-0.3.14-py3-none-any.whl.metadata (290 bytes)\n",
            "Collecting comfyui-workflow-templates-media-video==0.3.12 (from comfyui-workflow-templates==0.7.25->-r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates_media_video-0.3.12-py3-none-any.whl.metadata (282 bytes)\n",
            "Collecting comfyui-workflow-templates-media-image==0.3.17 (from comfyui-workflow-templates==0.7.25->-r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates_media_image-0.3.17-py3-none-any.whl.metadata (282 bytes)\n",
            "Collecting comfyui-workflow-templates-media-other==0.3.15 (from comfyui-workflow-templates==0.7.25->-r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates_media_other-0.3.15-py3-none-any.whl.metadata (305 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.5.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 5))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.50.3->-r requirements.txt (line 10)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.50.3->-r requirements.txt (line 10)) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.50.3->-r requirements.txt (line 10)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.50.3->-r requirements.txt (line 10)) (2.32.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl>=1.18.0->-r requirements.txt (line 15)) (3.11)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic->-r requirements.txt (line 21)) (1.3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy->-r requirements.txt (line 22)) (3.2.4)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia>=0.7.1->-r requirements.txt (line 26))\n",
            "  Downloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.0->-r requirements.txt (line 28)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.0->-r requirements.txt (line 28)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.0->-r requirements.txt (line 28)) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings~=2.0->-r requirements.txt (line 29)) (1.2.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.50.3->-r requirements.txt (line 10)) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.50.3->-r requirements.txt (line 10)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.50.3->-r requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.50.3->-r requirements.txt (line 10)) (2025.11.12)\n",
            "Downloading comfyui_frontend_package-1.33.10-py3-none-any.whl (18.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates-0.7.25-py3-none-any.whl (20 kB)\n",
            "Downloading comfyui_embedded_docs-0.3.1-py3-none-any.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates_core-0.3.12-py3-none-any.whl (27 kB)\n",
            "Downloading comfyui_workflow_templates_media_api-0.3.14-py3-none-any.whl (43.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates_media_image-0.3.17-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates_media_other-0.3.15-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates_media_video-0.3.12-py3-none-any.whl (31.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.7/31.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.2-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spandrel-0.4.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, kornia_rs, comfyui-workflow-templates-media-video, comfyui-workflow-templates-media-other, comfyui-workflow-templates-media-image, comfyui-workflow-templates-media-api, comfyui-workflow-templates-core, comfyui-frontend-package, comfyui-embedded-docs, av, comfyui-workflow-templates, torchsde, kornia, spandrel\n",
            "Successfully installed av-16.0.1 comfyui-embedded-docs-0.3.1 comfyui-frontend-package-1.33.10 comfyui-workflow-templates-0.7.25 comfyui-workflow-templates-core-0.3.12 comfyui-workflow-templates-media-api-0.3.14 comfyui-workflow-templates-media-image-0.3.17 comfyui-workflow-templates-media-other-0.3.15 comfyui-workflow-templates-media-video-0.3.12 kornia-0.8.2 kornia_rs-0.1.10 spandrel-0.4.1 torchsde-0.2.6 trampoline-0.1.2\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "ef2425|\u001b[1;32mOK\u001b[0m  |   172MiB/s|/content/ComfyUI/models/diffusion_models/z-image-turbo-fp8-e4m3fn.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "9e46b0|\u001b[1;32mOK\u001b[0m  |   185MiB/s|/content/ComfyUI/models/clip/qwen_3_4b.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "4013b0|\u001b[1;32mOK\u001b[0m  |   216MiB/s|/content/ComfyUI/models/vae/ae.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/comfyanonymous/ComfyUI\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors -d /content/ComfyUI/models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors -d /content/ComfyUI/models/clip -o qwen_3_4b.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors -d /content/ComfyUI/models/vae -o ae.safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GskGQjzIHopj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa898884-917a-4eb0-a430-c004bdb339c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ComfyUI\n",
        "\n",
        "import os, random, time\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "\n",
        "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "CLIPLoader = NODE_CLASS_MAPPINGS[\"CLIPLoader\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
        "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    unet = UNETLoader.load_unet(\"z-image-turbo-fp8-e4m3fn.safetensors\", \"fp8_e4m3fn_fast\")[0]\n",
        "    clip = CLIPLoader.load_clip(\"qwen_3_4b.safetensors\", type=\"lumina2\")[0]\n",
        "    vae = VAELoader.load_vae(\"ae.safetensors\")[0]\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(input):\n",
        "    tmp_dir=\"/content/ComfyUI/output\"\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "\n",
        "    values = input[\"input\"]\n",
        "\n",
        "    positive_prompt = values['positive_prompt']\n",
        "    negative_prompt = values['negative_prompt']\n",
        "    seed = values['seed'] # 0\n",
        "    steps = values['steps'] # 9\n",
        "    cfg = values['cfg'] # 1.0\n",
        "    sampler_name = values['sampler_name'] # euler\n",
        "    scheduler = values['scheduler'] # simple\n",
        "    denoise = values['denoise'] # 1.0\n",
        "    width = values['width'] # 1024\n",
        "    height = values['height'] # 1024\n",
        "    batch_size = values['batch_size'] # 1.0\n",
        "\n",
        "    if seed == 0:\n",
        "        random.seed(int(time.time()))\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "    positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
        "    negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
        "    latent_image = EmptyLatentImage.generate(width, height, batch_size=batch_size)[0]\n",
        "    samples = KSampler.sample(unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)[0]\n",
        "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
        "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"{tmp_dir}/z_image_turbo.png\")\n",
        "\n",
        "    result = f\"{tmp_dir}/z_image_turbo.png\"\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrisDYt7Hopk"
      },
      "outputs": [],
      "source": [
        "input = {\n",
        "  \"input\": {\n",
        "    \"positive_prompt\": \"一位男士和他的贵宾犬穿着配套的服装参加狗狗秀，室内灯光，背景中有观众。\",\n",
        "    \"negative_prompt\": \"blurry ugly bad\",\n",
        "    \"width\": 1024,\n",
        "    \"height\": 1024,\n",
        "    \"batch_size\": 1,\n",
        "    \"seed\": 0,\n",
        "    \"steps\": 9,\n",
        "    \"cfg\": 1,\n",
        "    \"sampler_name\": \"euler\",\n",
        "    \"scheduler\": \"simple\",\n",
        "    \"denoise\": 1.0,\n",
        "  }\n",
        "}\n",
        "\n",
        "output = generate(input)\n",
        "Image.open(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cbba279"
      },
      "source": [
        "Here's the `Dockerfile` you will use. Make sure to save this content as `Dockerfile` in the root of your project directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b774461",
        "outputId": "e735ecb4-f0e7-431b-fbf4-711f8880b475"
      },
      "source": [
        "%%writefile Dockerfile\n",
        "FROM python:3.12-slim-buster\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "# Install git and aria2c for cloning ComfyUI and downloading models\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "    git \\\n",
        "    aria2 \\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Clone ComfyUI repository\n",
        "RUN git clone https://github.com/comfyanonymous/ComfyUI /app/ComfyUI\n",
        "\n",
        "# Change working directory to ComfyUI\n",
        "WORKDIR /app/ComfyUI\n",
        "\n",
        "# Install ComfyUI requirements and FastAPI, Uvicorn, Pydantic, Pillow, NumPy, Torch, Transformers, Safetensors, Aiohttp, Yarl, PyYAML, SciPy, TQDM, Psutil, Alembic, SQLAlchemy, AV, Kornia, Spandrel.\n",
        "# Using separate pip install commands for better caching and specific dependencies\n",
        "RUN pip install --no-cache-dir -r requirements.txt \\\n",
        "    fastapi \\\n",
        "    uvicorn \\\n",
        "    pydantic \\\n",
        "    Pillow \\\n",
        "    numpy \\\n",
        "    torch \\\n",
        "    transformers \\\n",
        "    safetensors \\\n",
        "    aiohttp \\\n",
        "    yarl \\\n",
        "    pyyaml \\\n",
        "    scipy \\\n",
        "    tqdm \\\n",
        "    psutil \\\n",
        "    alembic \\\n",
        "    SQLAlchemy \\\n",
        "    av \\\n",
        "    kornia \\\n",
        "    spandrel\n",
        "\n",
        "# Create directories for models\n",
        "RUN mkdir -p models/diffusion_models models/clip models/vae\n",
        "\n",
        "# Download the required models using aria2c\n",
        "RUN aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors -d /app/ComfyUI/models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors\n",
        "RUN aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors -d /app/ComfyUI/models/clip -o qwen_3_4b.safetensors\n",
        "RUN aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors -d /app/ComfyUI/models/vae -o ae.safetensors\n",
        "\n",
        "# Copy the FastAPI application script into the container\n",
        "COPY app.py /app/ComfyUI/app.py\n",
        "\n",
        "# Expose the port FastAPI will run on\n",
        "EXPOSE 8000\n",
        "\n",
        "# Command to run the FastAPI application with Uvicorn\n",
        "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "XCIMrNq5Qn3I",
        "outputId": "95675c5c-6b9a-404c-ae01-7ad38aaad747"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a06e3657"
      },
      "source": [
        "Next, here is the `app.py` script. Save this content as `app.py` in the same directory as your `Dockerfile`. This script sets up a FastAPI endpoint to handle image generation requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fd26d79",
        "outputId": "fce0e108-31f2-46c2-c18c-143ba1a04725"
      },
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from starlette.responses import FileResponse\n",
        "\n",
        "# Ensure the ComfyUI nodes are importable from the current directory\n",
        "# This assumes the Dockerfile has already set WORKDIR to /app/ComfyUI\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"ComfyUI Image Generator API\",\n",
        "    description=\"An API to generate images using ComfyUI models.\",\n",
        "    version=\"1.0.0\",\n",
        ")\n",
        "\n",
        "# Initialize ComfyUI nodes and models outside the endpoint to load them once\n",
        "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "CLIPLoader = NODE_CLASS_MAPPINGS[\"CLIPLoader\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
        "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "# Load models\n",
        "# The Dockerfile ensures these models are present at /app/ComfyUI/models/...\n",
        "try:\n",
        "    with torch.inference_mode():\n",
        "        unet = UNETLoader.load_unet(\"z-image-turbo-fp8-e4m3fn.safetensors\", \"fp8_e4m3fn_fast\")[0]\n",
        "        clip = CLIPLoader.load_clip(\"qwen_3_4b.safetensors\", type=\"lumina2\")[0]\n",
        "        vae = VAELoader.load_vae(\"ae.safetensors\")[0]\n",
        "    print(\"Models loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "    # Depending on the deployment environment, you might want to exit or raise here\n",
        "    # For now, we'll let the app start but generation requests will fail\n",
        "\n",
        "class InputData(BaseModel):\n",
        "    positive_prompt: str = \"A man with his poodle in matching outfits at a dog show, indoor lighting, with an audience in the background.\"\n",
        "    negative_prompt: str = \"blurry ugly bad\"\n",
        "    width: int = 1024\n",
        "    height: int = 1024\n",
        "    batch_size: int = 1\n",
        "    seed: int = 0  # 0 for random seed\n",
        "    steps: int = 9\n",
        "    cfg: float = 1.0\n",
        "    sampler_name: str = \"euler\"\n",
        "    scheduler: str = \"simple\"\n",
        "    denoise: float = 1.0\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    return {\"status\": \"ok\", \"message\": \"API is running\"}\n",
        "\n",
        "@app.post(\"/generate\")\n",
        "async def generate_image(input_data: InputData):\n",
        "    tmp_dir = \"output\"\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "\n",
        "    positive_prompt = input_data.positive_prompt\n",
        "    negative_prompt = input_data.negative_prompt\n",
        "    seed = input_data.seed\n",
        "    steps = input_data.steps\n",
        "    cfg = input_data.cfg\n",
        "    sampler_name = input_data.sampler_name\n",
        "    scheduler = input_data.scheduler\n",
        "    denoise = input_data.denoise\n",
        "    width = input_data.width\n",
        "    height = input_data.height\n",
        "    batch_size = input_data.batch_size\n",
        "\n",
        "    if seed == 0:\n",
        "        random.seed(int(time.time()))\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "    try:\n",
        "        with torch.inference_mode():\n",
        "            positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
        "            negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
        "            latent_image = EmptyLatentImage.generate(width, height, batch_size=batch_size)[0]\n",
        "            samples = KSampler.sample(unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)[0]\n",
        "            decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
        "\n",
        "        output_path = os.path.join(tmp_dir, f\"z_image_turbo_{int(time.time())}.png\")\n",
        "        # Convert to numpy array and save\n",
        "        Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(output_path)\n",
        "\n",
        "        return FileResponse(output_path, media_type=\"image/png\", filename=os.path.basename(output_path))\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Image generation failed: {str(e)}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06836f86"
      },
      "source": [
        "## Deployment Instructions for Lightning.ai\n",
        "\n",
        "1.  **Save Files**: Make sure you have both `Dockerfile` and `app.py` in the same directory on your local machine.\n",
        "2.  **Lightning.ai Account**: Log in to your Lightning.ai account. If you don't have one, sign up.\n",
        "3.  **Create a New Component/App**: Navigate to your Lightning.ai dashboard and create a new 'Component' or 'App'.\n",
        "4.  **Select Docker Deployment**: Choose the 'Docker' deployment option. Lightning.ai will use your `Dockerfile` to build the image.\n",
        "5.  **Upload Files**: Upload your project directory containing `Dockerfile` and `app.py`. Lightning.ai will automatically detect and use your `Dockerfile`.\n",
        "6.  **Configure Service**: In the Lightning.ai configuration interface, you will need to specify:\n",
        "    *   **Port**: Ensure the exposed port is set to `8000`, matching what's defined in your `Dockerfile` and `app.py`.\n",
        "    *   **Health Check Endpoint**: Set the health check endpoint to `/health` (defined in `app.py`).\n",
        "    *   **Resource Allocation**: Select appropriate GPU and CPU resources, especially since image generation is GPU-intensive. Lightning.ai provides options for this.\n",
        "7.  **Deploy**: Initiate the deployment process. Lightning.ai will build your Docker image, which will include cloning ComfyUI and downloading the models, and then deploy your FastAPI application.\n",
        "8.  **Obtain Endpoint URL**: Once deployed successfully, Lightning.ai will provide a public endpoint URL for your service. This URL is what your `videolyricai.com` app in Google AI Studio will use.\n",
        "\n",
        "### How your `videolyricai.com` app in AI Studio will consume the API:\n",
        "\n",
        "Once deployed to Lightning.ai, you'll have an endpoint like `https://your-lightning-app-url.lightning.ai`. Your AI Studio app for `videolyricai.com` can then make HTTP POST requests to `https://your-lightning-app-url.lightning.ai/generate`.\n",
        "\n",
        "The POST request body should be a JSON object conforming to the `InputData` schema defined in `app.py` (e.g., `{\"positive_prompt\": \"your prompt\", \"negative_prompt\": \"bad quality\", \"width\": 1024, \"height\": 1024, ...}`). The API will respond with the generated image in PNG format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1021e17b"
      },
      "source": [
        "# Task\n",
        "Build a Docker image for the ComfyUI API using the `Dockerfile` and `app.py` files, push this image to Google Container Registry (GCR), and then deploy the pre-built image from GCR to Lightning.ai, with guidance on adapting this process for future model deployments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb4ce551"
      },
      "source": [
        "## Build Docker Image and Push to Google Container Registry\n",
        "\n",
        "### Subtask:\n",
        "Build the Docker image for the ComfyUI API using the provided Dockerfile and app.py, and push it to your Google Container Registry (GCR).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5364917"
      },
      "source": [
        "## Build Docker Image and Push to Google Container Registry\n",
        "\n",
        "### Subtask:\n",
        "Build the Docker image for the ComfyUI API using the provided Dockerfile and app.py, and push it to your Google Container Registry (GCR).\n",
        "\n",
        "#### Instructions\n",
        "1. Ensure you are authenticated to Google Cloud. If you haven't already, run `gcloud auth login` in your terminal and follow the prompts.\n",
        "2. Set your Google Cloud Project ID. Replace `YOUR_PROJECT_ID` with your actual Google Cloud Project ID by running: `gcloud config set project YOUR_PROJECT_ID`.\n",
        "3. Navigate to the directory where your `Dockerfile` and `app.py` are located.\n",
        "4. Submit the Dockerfile to Cloud Build to build the image and push it to Google Container Registry. Run the following command, replacing `YOUR_PROJECT_ID` with your Google Cloud Project ID: `gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:latest .`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1180e5f"
      },
      "source": [
        "## Build Docker Image and Push to Google Container Registry\n",
        "\n",
        "### Subtask:\n",
        "Build the Docker image for the ComfyUI API using the provided Dockerfile and app.py, and push it to your Google Container Registry (GCR).\n",
        "\n",
        "#### Instructions\n",
        "1. Ensure you are authenticated to Google Cloud. If you haven't already, run `gcloud auth login` in your terminal and follow the prompts.\n",
        "2. Set your Google Cloud Project ID. Replace `YOUR_PROJECT_ID` with your actual Google Cloud Project ID by running: `gcloud config set project YOUR_PROJECT_ID`.\n",
        "3. Navigate to the directory where your `Dockerfile` and `app.py` are located.\n",
        "4. Submit the Dockerfile to Cloud Build to build the image and push it to Google Container Registry. Run the following command, replacing `YOUR_PROJECT_ID` with your Google Cloud Project ID: `gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:latest .`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "758e2556"
      },
      "source": [
        "## Build Docker Image and Push to Google Container Registry\n",
        "\n",
        "### Subtask:\n",
        "Build the Docker image for the ComfyUI API using the provided Dockerfile and app.py, and push it to your Google Container Registry (GCR).\n",
        "\n",
        "#### Instructions\n",
        "1. Ensure you are authenticated to Google Cloud. If you haven't already, run `gcloud auth login` in your terminal and follow the prompts.\n",
        "2. Set your Google Cloud Project ID. Replace `YOUR_PROJECT_ID` with your actual Google Cloud Project ID by running: `gcloud config set project YOUR_PROJECT_ID`.\n",
        "3. Navigate to the directory where your `Dockerfile` and `app.py` are located.\n",
        "4. Submit the Dockerfile to Cloud Build to build the image and push it to Google Container Registry. Run the following command, replacing `YOUR_PROJECT_ID` with your Google Cloud Project ID: `gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:latest .`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7c2e9b7"
      },
      "source": [
        "## Deploy Pre-built Image to Lightning.ai\n",
        "\n",
        "### Subtask:\n",
        "Configure your Lightning.ai deployment to pull and use the pre-built Docker image directly from your Google Container Registry.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b630d635"
      },
      "source": [
        "## Deploy Pre-built Image to Lightning.ai\n",
        "\n",
        "### Subtask:\n",
        "Configure your Lightning.ai deployment to pull and use the pre-built Docker image directly from your Google Container Registry.\n",
        "\n",
        "#### Instructions\n",
        "1. Log in to your Lightning.ai account and navigate to your application dashboard.\n",
        "2. Create a new component or app, or edit an existing one.\n",
        "3. When configuring the deployment, select the option to deploy a 'Pre-built Docker Image'.\n",
        "4. Provide the full image path from your Google Container Registry (GCR). This will typically be in the format `gcr.io/YOUR_PROJECT_ID/comfyui-api:latest`. Replace `YOUR_PROJECT_ID` with your actual Google Cloud Project ID.\n",
        "5. Ensure that Lightning.ai has the necessary permissions to pull images from your GCR. This might involve configuring service account keys or repository access within Lightning.ai's settings.\n",
        "6. Set the exposed port to `8000`, matching the `EXPOSE` instruction in your `Dockerfile` and the port used by Uvicorn in `app.py`.\n",
        "7. Configure the health check endpoint to `/health`.\n",
        "8. Select appropriate GPU and CPU resources for your application.\n",
        "9. Initiate the deployment. Lightning.ai will pull the specified Docker image from your GCR and deploy your FastAPI application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "113707c1"
      },
      "source": [
        "## Guidance for Future Model Deployment (Revised)\n",
        "\n",
        "### Subtask:\n",
        "Reiterate how this Docker-based strategy, now with a focus on pre-building and storing images in GCR, can be adapted for your WAN2.2 KiNeTy fusion model. This will emphasize updating the Dockerfile and pushing a new image to GCR, then deploying that image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27c2a989"
      },
      "source": [
        "### Adapting the Docker-based Deployment Strategy for WAN2.2 KiNeTy Fusion Model\n",
        "\n",
        "To adapt this Docker-based deployment strategy for your WAN2.2 KiNeTy fusion model, the core idea is to treat your new model as a set of changes to the existing ComfyUI setup. This involves a clear lifecycle of modification, image building, and deployment:\n",
        "\n",
        "1.  **Modify the Dockerfile**: Your `Dockerfile` is the blueprint for your application's environment. You will need to:\n",
        "    *   **Update Repository Cloning**: If the WAN2.2 KiNeTy model lives in a different Git repository (e.g., a custom ComfyUI fork or a specific extension), modify the `git clone` command to point to the correct URL.\n",
        "    *   **Adjust Dependency Installation**: Add any new Python libraries (e.g., `pip install new-library`) or system-level packages (`apt-get install new-package`) that your WAN2.2 KiNeTy model requires into the Dockerfile.\n",
        "    *   **Specify New Model Downloads**: Crucially, update the `aria2c` commands to download the specific `.safetensors` or other model weight files for the WAN2.2 KiNeTy model. Ensure these are placed in the correct subdirectories within `/app/ComfyUI/models` (e.g., `diffusion_models`, `clip`, `vae`) as expected by ComfyUI.\n",
        "\n",
        "2.  **Adjust `app.py` for Model Loading**: The `app.py` script needs to be updated to load your specific WAN2.2 KiNeTy models. This will typically involve changing the model filenames in the `UNETLoader.load_unet`, `CLIPLoader.load_clip`, and `VAELoader.load_vae` calls to match the names of the files you downloaded in the Dockerfile.\n",
        "\n",
        "3.  **Build and Push to Google Container Registry (GCR)**:\n",
        "    *   Once your `Dockerfile` and `app.py` are updated, you'll rebuild your Docker image. It's essential to use a new, descriptive tag to denote this version with the WAN2.2 KiNeTy model. For example:\n",
        "        ```bash\n",
        "        gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:wan2.2-kinety .\n",
        "        ```\n",
        "    *   This command builds the Docker image using the `Dockerfile` in your current directory and pushes it to your specified GCR repository.\n",
        "\n",
        "4.  **Deploy the New Image to Lightning.ai**:\n",
        "    *   Finally, in your Lightning.ai deployment configuration, update the image reference to point to your newly pushed GCR image (e.g., `gcr.io/YOUR_PROJECT_ID/comfyui-api:wan2.2-kinety`).\n",
        "    *   Lightning.ai will then pull this new image and deploy your FastAPI application with the WAN2.2 KiNeTy fusion model enabled, ready to serve generation requests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b41c139"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the updated workflow, confirming the benefits of using GCR for image storage and explaining how your AI Studio app will consume the API from the Lightning.ai deployment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f4967dd"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**1. How is the workflow updated for model deployment?**\n",
        "The updated workflow involves building a Docker image for the ComfyUI API, pushing this image to Google Container Registry (GCR), and then deploying the pre-built image from GCR to Lightning.ai. For future model deployments, such as the WAN2.2 KiNeTy fusion model, the `Dockerfile` and `app.py` are modified to include the new model's dependencies and loading logic. A new Docker image is then built with a descriptive tag, pushed to GCR, and the Lightning.ai deployment is updated to use this new image.\n",
        "\n",
        "**2. What are the benefits of using GCR for image storage?**\n",
        "Using GCR for image storage provides a centralized, secure, and versioned repository for Docker images. It integrates seamlessly with Google Cloud's ecosystem, allowing for automated builds via Cloud Build and reliable image sourcing for deployments to platforms like Lightning.ai. This ensures consistency and simplifies the management of different model versions.\n",
        "\n",
        "**3. How will the AI Studio app consume the API from the Lightning.ai deployment?**\n",
        "The AI Studio app will consume the API by making standard HTTP requests to the exposed endpoint of the ComfyUI API running on Lightning.ai. The API, deployed via the Docker image from GCR, will handle the model inference and respond to these requests, effectively serving the WAN2.2 KiNeTy fusion model. The exposed port for the API is `8000`, and a health check is available at `/health`.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Docker Image Build and Push to GCR**: Comprehensive, step-by-step instructions were provided to build a Docker image for the ComfyUI API using `Dockerfile` and `app.py`, and to push it to Google Container Registry (GCR) via `gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/comfyui-api:latest .`.\n",
        "*   **Deployment to Lightning.ai**: Detailed guidance was furnished for configuring a Lightning.ai deployment to pull and use the pre-built Docker image from GCR. This included specifying the GCR image path, ensuring necessary permissions, and configuring the exposed port (`8000`) and health check endpoint (`/health`).\n",
        "*   **Adaptation for Future Models**: A clear strategy was outlined for adapting the Docker-based deployment for new models like the WAN2.2 KiNeTy fusion model. This involves:\n",
        "    *   Modifying the `Dockerfile` to update repository cloning, adjust dependencies, and specify new model downloads (e.g., using `aria2c` for `.safetensors` files).\n",
        "    *   Adjusting `app.py` to load the specific new models.\n",
        "    *   Rebuilding and pushing the Docker image to GCR with a new, descriptive tag (e.g., `gcr.io/YOUR_PROJECT_ID/comfyui-api:wan2.2-kinety`).\n",
        "    *   Updating the image reference in the Lightning.ai deployment configuration to point to the newly tagged image.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Version Control for Models**: The use of distinct Docker image tags for each model version (e.g., `comfyui-api:latest` vs. `comfyui-api:wan2.2-kinety`) is crucial for maintaining version control, enabling rollback capabilities, and facilitating parallel testing of different models.\n",
        "*   **Automate Deployment Pipeline**: To streamline future deployments and model updates, consider automating the entire process from `Dockerfile` modification to Lightning.ai deployment through a CI/CD pipeline (e.g., using Cloud Build, GitHub Actions, or similar tools) that triggers upon changes in the model's codebase or `Dockerfile`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "zKomery5RswT"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}